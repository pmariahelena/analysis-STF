{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Dados – Controle Concentrado de Constitucionalidade (STF)\n",
    "\n",
    "Notebook interativo para explorar os dados extraídos do portal do STF (ADIs, ADPFs, ADCs e ADOs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = \"ArquivosConcatenados_1.csv\"\n",
    "\n",
    "if not Path(CSV_PATH).exists():\n",
    "    CSV_PATH = \"Dados ADI de 6000 a 6010.csv\"\n",
    "    print(f\"ArquivosConcatenados_1.csv não encontrado, usando {CSV_PATH}\")\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(f\"Arquivo: {CSV_PATH}\")\n",
    "print(f\"Linhas: {len(df):,} | Colunas: {df.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"data_protocolo\"] = pd.to_datetime(df[\"data_protocolo\"], format=\"%d/%m/%Y\", errors=\"coerce\")\n",
    "df[\"ano\"] = df[\"data_protocolo\"].dt.year\n",
    "df[\"decada\"] = (df[\"ano\"] // 10 * 10).astype(\"Int64\")\n",
    "df[\"tem_liminar\"] = df[\"liminar\"].str.contains(\"MEDIDA LIMINAR\", na=False)\n",
    "\n",
    "UF_NAMES = {\n",
    "    \"AC\": \"Acre\", \"AL\": \"Alagoas\", \"AP\": \"Amapá\", \"AM\": \"Amazonas\",\n",
    "    \"BA\": \"Bahia\", \"CE\": \"Ceará\", \"DF\": \"Distrito Federal\", \"ES\": \"Espírito Santo\",\n",
    "    \"GO\": \"Goiás\", \"MA\": \"Maranhão\", \"MT\": \"Mato Grosso\", \"MS\": \"Mato Grosso do Sul\",\n",
    "    \"MG\": \"Minas Gerais\", \"PA\": \"Pará\", \"PB\": \"Paraíba\", \"PR\": \"Paraná\",\n",
    "    \"PE\": \"Pernambuco\", \"PI\": \"Piauí\", \"RJ\": \"Rio de Janeiro\",\n",
    "    \"RN\": \"Rio Grande do Norte\", \"RS\": \"Rio Grande do Sul\", \"RO\": \"Rondônia\",\n",
    "    \"RR\": \"Roraima\", \"SC\": \"Santa Catarina\", \"SP\": \"São Paulo\", \"SE\": \"Sergipe\",\n",
    "    \"TO\": \"Tocantins\",\n",
    "}\n",
    "df[\"origem_valida\"] = df[\"origem\"].where(df[\"origem\"].isin(UF_NAMES))\n",
    "df[\"estado_nome\"] = df[\"origem_valida\"].map(UF_NAMES)\n",
    "\n",
    "print(f\"Período: {df['ano'].min():.0f} – {df['ano'].max():.0f}\")\n",
    "print(f\"Classes: {df['classe'].unique().tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Parsing de Colunas Complexas\n",
    "\n",
    "As colunas `partes_total`, `andamentos_lista`, `decisões` e `deslocamentos_lista` contêm listas/dicts serializados como strings. Use as funções abaixo para convertê-las."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_json_col(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parse a column containing JSON-encoded strings.\"\"\"\n",
    "    def _try(val):\n",
    "        if pd.isna(val):\n",
    "            return []\n",
    "        try:\n",
    "            return json.loads(val)\n",
    "        except (json.JSONDecodeError, TypeError):\n",
    "            try:\n",
    "                return ast.literal_eval(val)\n",
    "            except Exception:\n",
    "                return []\n",
    "    return series.apply(_try)\n",
    "\n",
    "\n",
    "def parse_list_col(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Parse a column containing Python list literals.\"\"\"\n",
    "    def _try(val):\n",
    "        if pd.isna(val):\n",
    "            return []\n",
    "        try:\n",
    "            return ast.literal_eval(val)\n",
    "        except Exception:\n",
    "            return []\n",
    "    return series.apply(_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: parsear andamentos de um processo específico\n",
    "# (cuidado: parsear a coluna inteira é lento para ~6600 linhas)\n",
    "\n",
    "sample = df.iloc[0]\n",
    "andamentos = json.loads(sample[\"andamentos_lista\"]) if pd.notna(sample[\"andamentos_lista\"]) else []\n",
    "print(f\"Processo: {sample['nome_processo']}\")\n",
    "print(f\"Andamentos: {len(andamentos)}\")\n",
    "if andamentos:\n",
    "    print(f\"Primeiro: {andamentos[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploração Básica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"classe\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"status_processo\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"relator\"].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"origem_valida\"].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"classe\")[[\"len(andamentos_lista)\", \"len(decisões)\", \"len(partes_total)\", \"len(deslocamentos)\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Filtros e Consultas\n",
    "\n",
    "Modifique as células abaixo para filtrar os dados conforme sua necessidade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por classe\n",
    "adis = df[df[\"classe\"] == \"ADI\"]\n",
    "print(f\"ADIs: {len(adis):,}\")\n",
    "adis.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por status\n",
    "em_andamento = df[df[\"status_processo\"] == \"Em andamento\"]\n",
    "print(f\"Em andamento: {len(em_andamento):,}\")\n",
    "em_andamento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por relator\n",
    "relator = \"GILMAR MENDES\"  # altere conforme desejado\n",
    "df_relator = df[df[\"relator\"] == relator]\n",
    "print(f\"Processos de {relator}: {len(df_relator):,}\")\n",
    "df_relator[[\"nome_processo\", \"classe\", \"data_protocolo\", \"status_processo\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar por período\n",
    "recentes = df[df[\"ano\"] >= 2020]\n",
    "print(f\"Processos de 2020 em diante: {len(recentes):,}\")\n",
    "recentes.groupby([\"ano\", \"classe\"]).size().unstack(fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buscar processo por nome\n",
    "busca = \"6000\"  # altere conforme desejado\n",
    "resultado = df[df[\"nome_processo\"].str.contains(busca, case=False, na=False)]\n",
    "print(f\"Resultados para '{busca}': {len(resultado)}\")\n",
    "resultado[[\"nome_processo\", \"classe\", \"relator\", \"autor1\", \"status_processo\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Análise de Andamentos (por processo)\n",
    "\n",
    "Como as colunas de andamentos e partes são muito grandes, é melhor trabalhar processo a processo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_andamentos(processo_nome: str) -> pd.DataFrame:\n",
    "    \"\"\"Retorna os andamentos de um processo como DataFrame.\"\"\"\n",
    "    row = df[df[\"nome_processo\"] == processo_nome].iloc[0]\n",
    "    raw = row[\"andamentos_lista\"]\n",
    "    try:\n",
    "        items = json.loads(raw)\n",
    "    except Exception:\n",
    "        items = ast.literal_eval(raw) if pd.notna(raw) else []\n",
    "    return pd.DataFrame(items)\n",
    "\n",
    "\n",
    "def get_partes(processo_nome: str) -> pd.DataFrame:\n",
    "    \"\"\"Retorna as partes de um processo como DataFrame.\"\"\"\n",
    "    row = df[df[\"nome_processo\"] == processo_nome].iloc[0]\n",
    "    raw = row[\"partes_total\"]\n",
    "    try:\n",
    "        items = json.loads(raw)\n",
    "    except Exception:\n",
    "        items = ast.literal_eval(raw) if pd.notna(raw) else []\n",
    "    return pd.DataFrame(items)\n",
    "\n",
    "\n",
    "def get_decisoes(processo_nome: str) -> pd.DataFrame:\n",
    "    \"\"\"Retorna as decisões de um processo como DataFrame.\"\"\"\n",
    "    row = df[df[\"nome_processo\"] == processo_nome].iloc[0]\n",
    "    raw = row[\"decisões\"]\n",
    "    try:\n",
    "        items = json.loads(raw)\n",
    "    except Exception:\n",
    "        items = ast.literal_eval(raw) if pd.notna(raw) else []\n",
    "    return pd.DataFrame(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo: andamentos do primeiro processo\n",
    "processo = df[\"nome_processo\"].iloc[0]\n",
    "and_df = get_andamentos(processo)\n",
    "print(f\"Andamentos de {processo}: {len(and_df)}\")\n",
    "and_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exportar Subconjuntos\n",
    "\n",
    "Use as células abaixo para salvar filtros ou transformações em novos arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar colunas leves (sem andamentos/partes/decisões) para Excel\n",
    "cols_leves = [\n",
    "    \"incidente\", \"classe\", \"nome_processo\", \"classe_extenso\",\n",
    "    \"tipo_processo\", \"liminar\", \"origem\", \"relator\", \"autor1\",\n",
    "    \"len(partes_total)\", \"data_protocolo\", \"origem_orgao\",\n",
    "    \"lista_assuntos\", \"len(andamentos_lista)\", \"len(decisões)\",\n",
    "    \"len(deslocamentos)\", \"status_processo\",\n",
    "]\n",
    "\n",
    "# df[cols_leves].to_csv(\"dados_leves.csv\", index=False)\n",
    "# df[cols_leves].to_excel(\"dados_leves.xlsx\", index=False)\n",
    "# print(\"Exportado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Espaço Livre\n",
    "\n",
    "Células em branco para suas análises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
